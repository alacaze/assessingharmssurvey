

,-------------------.
|  BIBTEX ENTRIES   |
`-------------------'

@article{Cumming2001,
  author =        {Cumming, Geoff and Finch, Sue},
  journal =       {Educational and Psychological Measurement},
  number =        {4},
  pages =         {532--574},
  title =         {{A Primer on the Understanding, Use, and Calculation
                   of Confidence Intervals that are Based on Central and
                   Noncentral Distributions}},
  volume =        {61},
  year =          {2001},
  abstract =      {Reform of statistical practice in the social and
                   behavioral sciences requires wider use of confidence
                   intervals (CIs), effect size measures, and
                   meta-analysis. The authors discuss four reasons for
                   promoting use of CIs: They (a) are readily
                   interpretable, (b) are linked to familiar statistical
                   significance tests, (c) can encourage meta-analytic
                   thinking, and (d) give information about precision.
                   The authors discuss calculation of CIs for a basic
                   standardized effect size measure, Cohen's $\delta$
                   (also known as Cohen's d), and contrast these with
                   the familiar CIs for original score means. CIs for
                   $\delta$ require use of noncentral t distributions,
                   which the authors apply also to statistical power and
                   simple meta-analysis of standardized effect sizes.
                   They provide the ESCI graphical software, which runs
                   under Microsoft Excel, to illustrate the discussion.
                   Wider use of CIs for $\delta$ and other effect size
                   measures should help promote highly desirable reform
                   of statistical practice in the social sciences.},
  doi =           {10.1177/0013164401614002},
}

@article{Doll2005,
  author =        {Doll, H},
  journal =       {Evidence-Based Medicine},
  number =        {5},
  pages =         {133--134},
  title =         {{Statistical approaches to uncertainty: p values and
                   confidence intervals unpacked}},
  volume =        {10},
  year =          {2005},
  doi =           {10.1136/ebm.10.5.133},
  issn =          {1356-5524},
}

@article{Falk1995,
  address =       {Thousand Oaks},
  author =        {Falk, Ruma and Greenbaum, Charles W},
  journal =       {Theory {\&} psychology},
  number =        {1},
  pages =         {75--98},
  publisher =     {Sage Publications},
  title =         {{Significance Tests Die Hard: The Amazing Persistence
                   of a Probabilistic Misconception}},
  volume =        {5},
  year =          {1995},
  abstract =      {We present a critique showing the flawed logical
                   structure of statistical significance tests. We then
                   attempt to analyze why, in spite of this faulty
                   reasoning, the use of significance tests persists. We
                   identify the illusion of probabilistic proof by
                   contradiction as a central stumbling block, because
                   it is based on a misleading generalization of
                   reasoning from logic to inference under uncertainty.
                   We present new data from a student sample and
                   examples from the psychological literature showing
                   the strength and prevalence of this illusion. We
                   identify some intrinsic cognitive mechanisms
                   (similarity to modus tollens reasoning; verbal
                   ambiguity in describing the meaning of significance
                   tests; and the need to rule out chance findings) and
                   extrinsic social pressures which help to maintain the
                   illusion. We conclude by mentioning some alternative
                   methods for presenting and analyzing psychological
                   data, none of which can be considered the ultimate
                   method.},
  issn =          {0959-3543},
}

@article{Fidler2009,
  address =       {Loftus},
  author =        {Fidler, Fiona and Loftus, Geoffrey R},
  journal =       {Zeitschrift f{\"{u}}r Psychologie/Journal of
                   Psychology},
  number =        {1},
  pages =         {27--37},
  publisher =     {Hogrefe {\&} Huber Publishers},
  title =         {{Why figures with error bars should replace p values:
                   Some conceptual arguments and empirical
                   demonstrations.}},
  volume =        {217},
  year =          {2009},
  abstract =      {Null-hypothesis significance testing (NHST) is the
                   primary means by which data are analyzed and
                   conclusions made, particularly in the social
                   sciences, but in other sciences as well (notably
                   ecology and economics). Despite this supremacy
                   however, numerous problems exist with NHST as a means
                   of interpreting and understanding data. These
                   problems have been articulated by various observers
                   over the years, but are being taken seriously by
                   researchers only slowly, if at all, as evidenced by
                   the continuing emphasis on NHST in statistics
                   classes, statistics textbooks, editorial policies
                   and, of course, the day-to-day practices reported in
                   empirical articles themselves (Cumming et al., 2007).
                   Over the past several decades, observers have
                   suggested a simpler approach? plotting the data with
                   appropriate confidence intervals (CIs) around
                   relevant sample statistics? to supplement or take the
                   place of hypothesis testing. This article addresses
                   these issues. (PsycINFO Database Record (c) 2016 APA,
                   all rights reserved)},
  doi =           {10.1027/0044-3409.217.1.27},
  issn =          {0044-3409(Print)},
}

@incollection{Gigerenzer2004,
  address =       {Thousand Oaks},
  author =        {Gigerenzer, Gerd and Krauss, Stefan and
                   Vitouch, Oliver},
  booktitle =     {The SAGE Handbook of Quantitative Methodology for the
                   Social Sciences},
  publisher =     {SAGE Publications, Inc},
  title =         {{The Null Ritual: What You Always Wanted to Know
                   About Significance Testing but Were Afraid to Ask}},
  year =          {2004},
  abstract =      {`This Handbook discusses important methodological
                   tools and topics in quantitative methodology in easy
                   to understand language. It is an exhaustive review of
                   past and recent advances in each topic combined with
                   a detailed discussion of examples and graphical
                   illustrations. It will be an essential reference for
                   social science researchers as an introduction to
                   methods and quantitative concepts of great use' -
                   Irini Moustaki, London School of Economics. `The 24
                   chapters in this Handbook span a wide range of
                   topics, presenting the latest quantitative
                   developments in scaling theory, measurement,
                   categorical data analysis, multilevel models, latent
                   variable models, and foundational issues. Each
                   chapter reviews the historical context for the topic
                   and then describes current work, including
                   illustrative examples where appropriate. The level of
                   presentation throughout the book is detailed enough
                   to convey genuine understanding without overwhelming
                   the reader with technical material. Ample references
                   are given for readers who wish to pursue topics in
                   more detail. The book will appeal to both researchers
                   who wish to update their knowledge of specific
                   quantitative methods, and students who wish to have
                   an integrated survey of state-of- the-art
                   quantitative methods' - Roger E Millsap, Arizona
                   State University. The SAGE Handbook of Quantitative
                   Methodology for the Social Sciences is the definitive
                   reference for teachers, students, and researchers of
                   quantitative methods in the social sciences, as it
                   provides a comprehensive overview of the major
                   techniques used in the field. The contributors, top
                   methodologists and researchers, have written about
                   their areas of expertise in ways that convey the
                   utility of their respective techniques, but, where
                   appropriate, they also offer a fair critique of these
                   techniques. Relevance to real-world problems in the
                   social sciences is an essential ingredient of each
                   chapter and makes this an invaluable resource. The
                   Handbook is divided into six sections: Scaling.
                   Testing and Measurement. Models for Categorical Data.
                   Models for Multilevel Data. Models for Latent
                   Variables. Foundational Issues. These sections,
                   comprising twenty-four chapters, address topics in
                   scaling and measurement, advances in statistical
                   modeling methodologies, and broad philosophical
                   themes and foundational issues that transcend many of
                   the quantitative methodologies covered in the book.
                   The Handbook is indispensable to the teaching, study,
                   and research of quantitat{\ldots}},
  isbn =          {9780761923596},
}

@article{Haller2002,
  author =        {Haller, Heiko and Krauss, Stefan},
  journal =       {Methods of psychological research MPR},
  pages =         {1--20},
  title =         {{Misinterpretations of significance: A problem
                   students share with their teachers?}},
  volume =        {7},
  year =          {2002},
  issn =          {1432-8534},
}

@article{Hemming2021,
  address =       {Australia},
  author =        {Hemming, Karla and Taljaard, Monica and Attia, John R and
                   Jones, Michael P},
  journal =       {Medical journal of Australia},
  number =        {3},
  pages =         {116----118.e1},
  title =         {{Why proper understanding of confidence intervals and
                   statistical significance is important}},
  volume =        {214},
  year =          {2021},
  issn =          {0025-729X},
}

@article{Hoekstra:2014hf,
  author =        {Hoekstra, Rink and Morey, Richard D and
                   Rouder, Jeffrey N and Wagenmakers, Eric-Jan},
  journal =       {Psychonomic Bulletin {\{}{\&}{\}} Review},
  month =         {jan},
  title =         {{Robust misinterpretation of confidence intervals}},
  year =          {2014},
  doi =           {10.3758/s13423-013-0572-3},
  url =           {http://link.springer.com/10.3758/s13423-013-0572-3},
}

@article{Lecoutre2003,
  author =        {Lecoutre, Marie‐Paule and Poitevineau, Jacques and
                   Lecoutre, Bruno},
  journal =       {International journal of psychology},
  number =        {1},
  pages =         {37--45},
  title =         {{Even statisticians are not immune to
                   misinterpretations of Null Hypothesis Significance
                   Tests}},
  volume =        {38},
  year =          {2003},
  abstract =      {We investigated the way experienced users interpret
                   Null Hypothesis Significance Testing (NHST) outcomes.
                   An empirical study was designed to compare the
                   reactions of two populations of NHST users,
                   psychological researchers and professional applied
                   statisticians, when faced with contradictory
                   situations. The subjects were presented with the
                   results of an experiment designed to test the
                   efficacy of a drug by comparing two groups
                   (treatment/placebo). Four situations were constructed
                   by combining the outcome of the t test (significant
                   vs. nonsignificant) and the observed difference
                   between the two means D (large vs. small). Two of
                   these situations appeared as conflicting (t
                   significant/D small and t nonsignificant/D large).
                   Three fundamental aspects of statistical inference
                   were investigated by means of open questions: drawing
                   inductive conclusions about the magnitude of the true
                   difference from the data in hand, making predictions
                   for future data, and making decisions about stopping
                   the experiment. The subjects were 25 statisticians
                   from pharmaceutical companies in France, subjects
                   well versed in statistics, and 20 psychological
                   researchers from various laboratories in France, all
                   with experience in processing and analyzing
                   experimental data. On the whole, statisticians and
                   psychologists reacted in a similar way and were very
                   impressed by significant results. It must be outlined
                   that professional applied statisticians were not
                   immune to misinterpretations, especially in the case
                   of nonsignificance. However, the interpretations that
                   accustomed users attach to the outcome of NHST can
                   vary from one individual to another, and it is hard
                   to conceive that there could be a consensus in the
                   face of seemingly conflicting situations. In fact,
                   beyond the superficial report of “erroneous”
                   interpretations, it can be seen in the misuses of
                   NHST intuitive judgmental “adjustments” that try
                   to overcome its inherent shortcomings. These findings
                   encourage the many recent attempts to improve the
                   habitual ways of analyzing and reporting experimental
                   data. Nous avons {\'{e}}tudi{\'{e}} la mani{\`{e}}re
                   dont des utilisateurs exp{\'{e}}riment{\'{e}}s
                   interpr{\`{e}}tent les r{\'{e}}sultats des Tests de
                   Signification de l'Hypoth{\`{e}}se Nulle. Une
                   {\'{e}}tude empirique a {\'{e}}t{\'{e}} men{\'{e}}e
                   pour comparer les r{\'{e}}actions de deux populations
                   d'utilisateurs, des chercheurs en psychologie et des
                   statisticiens professionnels, face {\`{a}} des
                   situations conflictuelles. On pr{\'{e}}sentait aux
                   sujets les r{\'{e}}sultats d'une exp{\'{e}}rience
                   planifi{\'{e}}e pour tester l'efficaci{\ldots}},
  issn =          {0020-7594},
}

@article{Neyman1937,
  author =        {Neyman, J},
  journal =       {Philosophical Transactions of the Royal Society of
                   London. Series A, Mathematical and Physical Sciences},
  month =         {mar},
  number =        {767},
  pages =         {333--380},
  publisher =     {The Royal Society},
  title =         {{Outline of a Theory of Statistical Estimation Based
                   on the Classical Theory of Probability}},
  volume =        {236},
  year =          {1937},
  issn =          {00804614},
}

@book{Oakes1986,
  address =       {Chichester ; New York},
  author =        {Oakes, Michael W},
  booktitle =     {Statistical inference : a commentary for the social
                   and behavioural sciences},
  publisher =     {Wiley},
  title =         {{Statistical inference : a commentary for the social
                   and behavioural sciences / Michael Oakes.}},
  year =          {1986},
  isbn =          {0471104434},
}

@article{Wulff1987,
  address =       {England},
  author =        {Wulff, H R and Andersen, B and Brandenhoff, P and
                   Guttler, F},
  journal =       {Statistics in medicine},
  number =        {1},
  pages =         {3--10},
  title =         {{What do doctors know about statistics?}},
  volume =        {6},
  year =          {1987},
  abstract =      {A multiple choice test with nine statistical
                   questions was sent to a random sample of Danish
                   doctors to assess their knowledge of elementary
                   statistical expressions (SD, SE, p less than 0.05, p
                   greater than 0.05 and r). One hundred and forty eight
                   (59 per cent) of 250 doctors answered the questions.
                   The test was also completed by 97 participants in
                   postgraduate courses in research methods, mainly
                   junior hospital doctors. The median number of correct
                   answers was 2.4 in the random sample and 4.0 in the
                   other sample of doctors. It is concluded that the
                   statistical knowledge of most doctors is so limited
                   that they cannot be expected to draw the right
                   conclusions from those statistical analyses which are
                   found in papers in medical journals. Sixty-five per
                   cent of the doctors in the random sample stated that
                   it is very important that this problem is raised.},
  doi =           {10.1002/sim.4780060103},
  issn =          {0277-6715 (Print)},
  language =      {eng},
}

